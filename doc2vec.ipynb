{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Data Analytics Acceleration Library (Intel(R) DAAL) solvers for sklearn enabled: https://intelpython.github.io/daal4py/sklearn.html\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes_classifier.load_data import str2word_bag\n",
    "from naive_bayes_classifier.configure import *\n",
    "from back_test import *\n",
    "from utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_se, rst_lst = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2sentence(orig_str):\n",
    "    sen_lst = orig_str.split(\".\")\n",
    "    \n",
    "    rst_lst = []\n",
    "    for sentence in sen_lst:\n",
    "        wd_lst = sentence.lower().split(\" \")\n",
    "        \n",
    "        for c in STOP_CHARS:\n",
    "            sentence = sentence.replace(c, \"\")\n",
    "        \n",
    "        for swd in STOP_WORDS:\n",
    "            try:\n",
    "                wd_lst = list(filter(lambda x: x!= swd, wd_lst))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            \n",
    "        sentence2 = \" \".join(wd_lst)\n",
    "            \n",
    "        if sentence2 != \"\":\n",
    "            rst_lst.append(sentence2.strip())\n",
    "    \n",
    "    return rst_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sen_by_atc_lst = [(i, str2sentence(ctt[2])) for i, ctt in enumerate(rst_lst)]\n",
    "sen_lst = reduce(lambda x, y: x + y, [ctt[1] for ctt in sen_by_atc_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"sen_lst\", \"wb\") as fp:\n",
    "    pickle.dump(sen_lst, fp)\n",
    "    \n",
    "with open(\"sen_by_atc_lst\", \"wb\") as fp:\n",
    "    pickle.dump(sen_by_atc_lst, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sen_lst\", \"rb\") as fp:\n",
    "    sen_lst = pickle.load(fp)\n",
    "    \n",
    "with open(\"sen_by_atc_lst\", \"rb\") as fp:\n",
    "    sen_by_atc_lst = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_train(sen_lst):\n",
    "    X_train = []\n",
    "    for i, sentence in enumerate(sen_lst):\n",
    "        word_lst = sentence.split(\" \")\n",
    "        document = gensim.models.doc2vec.TaggedDocument(word_lst, tags=[i]) \n",
    "        X_train.append(document)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_X_train(sen_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(X_train, min_coun=1, window=3, workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec.load(\"d2v.pymdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_mat = np.zeros((len(sen_by_atc_lst), 100))\n",
    "\n",
    "for atc_tpl in tqdm(sen_by_atc_lst):\n",
    "    tmp_lst = []\n",
    "    \n",
    "    for sentence in atc_tpl[1]:\n",
    "        try:\n",
    "            tmp_lst.append(model.infer_vector(sentence.split(\" \")))\n",
    "        except TypeError:\n",
    "            pass\n",
    "    try:\n",
    "        X_mat[atc_tpl[0], :] = np.mean(np.vstack(tmp_lst), axis=0)\n",
    "    except:\n",
    "        X_mat[atc_tpl[0], :] = np.zeros(100,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.save(\"X_mat\", X_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"atc_lst\", \"rb\") as fp:\n",
    "    atc_lst = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec.load(\"d2v.pymdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec_backtest(rst_lst, embedding_model=gensim.models.doc2vec.Doc2Vec.load(\"d2v_no_train.pymdl\"), batch_count=10):\n",
    "    n_samples = len(rst_lst) // batch_count    \n",
    "    \n",
    "    X_train_vec_lst = []\n",
    "    X_test_vec_lst = []\n",
    "    \n",
    "    for b_id in tqdm(range(batch_count - 2)):\n",
    "        print(\"create X\")\n",
    "        this_X_train = [get_X_train(str2sentence(ctt[2])) for ctt in rst_lst[b_id*n_samples : (b_id+1)*n_samples]]\n",
    "        print(\"X created\")\n",
    "        \n",
    "        print(\"training\")\n",
    "        model.train(reduce(lambda x, y: x+y, this_X_train), total_examples=n_samples, epochs=500)\n",
    "        print(\"train done\")\n",
    "    \n",
    "        # get train vec rep\n",
    "        print(\"predicting insample\")\n",
    "        this_X_train_vec = np.zeros((len(this_X_train), 100))\n",
    "        for a_id, atc in enumerate(this_X_train):\n",
    "            this_atc_vec = np.zeros((1, 100))\n",
    "            \n",
    "            for sentence in atc:\n",
    "                this_atc_vec += model.infer_vector(sentence[0])\n",
    "            \n",
    "            this_X_train_vec[a_id, :] = this_atc_vec / len(atc)\n",
    "        \n",
    "        X_train_vec_lst.append(this_X_train_vec)\n",
    "        print(\"prediction done\")\n",
    "        \n",
    "        # get test vec rep\n",
    "        print(\"predicting out sample\")\n",
    "        this_X_test = X[(b_id+1)*n_samples : (b_id+2)*n_samples]\n",
    "\n",
    "        this_X_test_vec = np.zeros((len(this_X_test), 1))\n",
    "        for a_id, atc in enumerate(this_X_test):\n",
    "            this_atc_vec = np.zeros((1, 100))\n",
    "            \n",
    "            for sentence in atc:\n",
    "                this_atc_vec += model.infer_vector(sentence[0])\n",
    "            \n",
    "            this_X_test_vec[a_id, :] = this_atc_vec / len(atc)\n",
    "        \n",
    "        X_test_vec_lst.append(this_X_test_vec)\n",
    "        print(\"prediction done\")\n",
    "        \n",
    "    return X_train_vec_lst, X_test_vec_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create X\n",
      "X created\n",
      "training\n"
     ]
    }
   ],
   "source": [
    "X_train_vec_lst, X_test_vec_lst = doc2vec_backtest(rst_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
