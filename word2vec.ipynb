{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20598eeb950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see http://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 49\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "split_ind = (int)(len(text) * 0.8)\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(text)\n",
    "vocab_size = len(vocab)\n",
    "print('vocab_size:', vocab_size)\n",
    "\n",
    "w2i = {w: i for i, w in enumerate(vocab)}\n",
    "i2w = {i: w for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow sample (['We', 'are', 'to', 'study'], 'about')\n",
      "skipgram sample ('about', 'We', 1)\n"
     ]
    }
   ],
   "source": [
    "# context window size is two\n",
    "def create_cbow_dataset(text):\n",
    "    data = []\n",
    "    for i in range(2, len(text) - 2):\n",
    "        context = [text[i - 2], text[i - 1],\n",
    "                   text[i + 1], text[i + 2]]\n",
    "        target = text[i]\n",
    "        data.append((context, target))\n",
    "    return data\n",
    "\n",
    "def create_skipgram_dataset(text):\n",
    "    import random\n",
    "    data = []\n",
    "    for i in range(2, len(text) - 2):\n",
    "        data.append((text[i], text[i-2], 1))\n",
    "        data.append((text[i], text[i-1], 1))\n",
    "        data.append((text[i], text[i+1], 1))\n",
    "        data.append((text[i], text[i+2], 1))\n",
    "        # negative sampling\n",
    "        for _ in range(4):\n",
    "            if random.random() < 0.5 or i >= len(text) - 3:\n",
    "                rand_id = random.randint(0, i-1)\n",
    "            else:\n",
    "                rand_id = random.randint(i+3, len(text)-1)\n",
    "            data.append((text[i], text[rand_id], 0))\n",
    "    return data\n",
    "\n",
    "cbow_train = create_cbow_dataset(text)\n",
    "skipgram_train = create_skipgram_dataset(text)\n",
    "print('cbow sample', cbow_train[0])\n",
    "print('skipgram sample', skipgram_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size, context_size, hidden_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_size)\n",
    "        self.linear1 = nn.Linear(2*context_size*embd_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embeddings(inputs).view((1, -1))\n",
    "        hid = F.relu(self.linear1(embedded))\n",
    "        out = self.linear2(hid)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs\n",
    "\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embd_size)\n",
    "    \n",
    "    def forward(self, focus, context):\n",
    "        embed_focus = self.embeddings(focus).view((1, -1))\n",
    "        embed_ctx = self.embeddings(context).view((1, -1))\n",
    "        score = torch.mm(embed_focus, torch.t(embed_ctx))\n",
    "        log_probs = F.logsigmoid(score)\n",
    "    \n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW(\n",
      "  (embeddings): Embedding(49, 100)\n",
      "  (linear1): Linear(in_features=400, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=49, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoore\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram(\n",
      "  (embeddings): Embedding(49, 100)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embd_size = 100\n",
    "learning_rate = 0.001\n",
    "n_epoch = 30\n",
    "\n",
    "def train_cbow():\n",
    "    hidden_size = 64\n",
    "    losses = []\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    model = CBOW(vocab_size, embd_size, CONTEXT_SIZE, hidden_size)\n",
    "    print(model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = .0\n",
    "        for context, target in cbow_train:\n",
    "            ctx_idxs = [w2i[w] for w in context]\n",
    "            ctx_var = Variable(torch.LongTensor(ctx_idxs))\n",
    "\n",
    "            model.zero_grad()\n",
    "            log_probs = model(ctx_var)\n",
    "\n",
    "            loss = loss_fn(log_probs, Variable(torch.LongTensor([w2i[target]])))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.data\n",
    "        losses.append(total_loss)\n",
    "    return model, losses\n",
    "\n",
    "def train_skipgram():\n",
    "    losses = []\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model = SkipGram(vocab_size, embd_size)\n",
    "    print(model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = .0\n",
    "        for in_w, out_w, target in skipgram_train:\n",
    "            in_w_var = Variable(torch.LongTensor([w2i[in_w]]))\n",
    "            out_w_var = Variable(torch.LongTensor([w2i[out_w]]))\n",
    "            \n",
    "            model.zero_grad()\n",
    "            log_probs = model(in_w_var, out_w_var)\n",
    "            loss = loss_fn(log_probs[0], Variable(torch.Tensor([target])))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.data\n",
    "        losses.append(total_loss)\n",
    "    return model, losses\n",
    "    \n",
    "cbow_model, cbow_losses = train_cbow()\n",
    "sg_model, sg_losses = train_skipgram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "====Test SkipGram===\n",
      "Accuracy: 50.0% (232/464)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# You have to use other dataset for test, but in this case I use training data because this dataset is too small\n",
    "def test_cbow(test_data, model):\n",
    "    print('====Test CBOW===')\n",
    "    correct_ct = 0\n",
    "    for ctx, target in test_data:\n",
    "        ctx_idxs = [w2i[w] for w in ctx]\n",
    "        ctx_var = Variable(torch.LongTensor(ctx_idxs))\n",
    "\n",
    "        model.zero_grad()\n",
    "        log_probs = model(ctx_var)\n",
    "        _, predicted = torch.max(log_probs.data, 1)\n",
    "        predicted_word = i2w[predicted[0]]\n",
    "        print('predicted:', predicted_word)\n",
    "        print('label    :', target)\n",
    "        if predicted_word == target:\n",
    "            correct_ct += 1\n",
    "            \n",
    "    print('Accuracy: {:.1f}% ({:d}/{:d})'.format(correct_ct/len(test_data)*100, correct_ct, len(test_data)))\n",
    "\n",
    "def test_skipgram(test_data, model):\n",
    "    print('====Test SkipGram===')\n",
    "    correct_ct = 0\n",
    "    for in_w, out_w, target in test_data:\n",
    "        in_w_var = Variable(torch.LongTensor([w2i[in_w]]))\n",
    "        out_w_var = Variable(torch.LongTensor([w2i[out_w]]))\n",
    "\n",
    "        model.zero_grad()\n",
    "        log_probs = model(in_w_var, out_w_var)\n",
    "        _, predicted = torch.max(log_probs.data, 1)\n",
    "        predicted = predicted[0]\n",
    "        if predicted == target:\n",
    "            correct_ct += 1\n",
    "\n",
    "    print('Accuracy: {:.1f}% ({:d}/{:d})'.format(correct_ct/len(test_data)*100, correct_ct, len(test_data)))\n",
    "\n",
    "#test_cbow(cbow_train, cbow_model)\n",
    "print('------')\n",
    "test_skipgram(skipgram_train, sg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqQGhoMkqYHhIElqYDhIkhr8f2nj+H0EJzj+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points, title):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "\n",
    "#showPlot(cbow_losses, 'CBOW Losses')\n",
    "showPlot(sg_losses, 'SkipGram Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
